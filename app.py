import os
import streamlit as st
from transformers import AutoModel, AutoTokenizer
from PIL import Image
import torch
import tempfile
import traceback
from dotenv import load_dotenv
from patch_model import patch_deepseek_for_cpu

load_dotenv()

MODEL_PATH = os.getenv("DEEPSEEK_MODEL_PATH", "deepseek-ai/DeepSeek-OCR")

if not torch.cuda.is_available():
    try:
        patch_deepseek_for_cpu()
    except Exception as e:
        print(f"íŒ¨ì¹˜ ì¤‘ ì˜¤ë¥˜: {e}")

st.set_page_config(
    page_title="DeepSeek OCR",
    page_icon="ğŸ“„",
    layout="wide"
)

@st.cache_resource
def download_model():
    """ëª¨ë¸ì„ ë¨¼ì € ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        st.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {MODEL_PATH}")
        
        # í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained(
            MODEL_PATH,
            trust_remote_code=True
        )
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        model = AutoModel.from_pretrained(
            MODEL_PATH,
            trust_remote_code=True,
            use_safetensors=True
        )
        
        st.success("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return model, tokenizer
    except Exception as e:
        st.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())
        return None, None

@st.cache_resource
def load_model():
    """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ì— ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # ë¨¼ì € ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        model, tokenizer = download_model()
        if model is None or tokenizer is None:
            return None, None
        
        st.info("ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ì— ë¡œë“œ ì¤‘...")
        
        if torch.cuda.is_available():
            device = torch.device("cuda")
            device_name = "CUDA (NVIDIA GPU)"
            dtype = torch.bfloat16
        else:
            device = torch.device("cpu")
            device_name = "CPU"
            dtype = torch.float32
        
        st.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device_name} (dtype: {dtype})")
        
        # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ì— ë¡œë“œ
        model = model.eval().to(device=device, dtype=dtype)
        
        return model, tokenizer
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.error(traceback.format_exc())
        return None, None

def extract_text_from_image(model, tokenizer, image, prompt_type, custom_prompt=None):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tmp_file:
            image.save(tmp_file.name, format='JPEG')
            image_file = tmp_file.name
        
        if prompt_type == "free_ocr":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "markdown":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "
        
        with tempfile.TemporaryDirectory() as output_dir:
            res = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=image_file,
                output_path=output_dir,
                base_size=1024,
                image_size=640,
                crop_mode=True,
                save_results=False,
                test_compress=False,
                eval_mode=True
            )
        
        try:
            os.unlink(image_file)
        except:
            pass
        
        if res is None:
            return "ì˜¤ë¥˜: ëª¨ë¸ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        return res
    except Exception as e:
        error_msg = f"ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n\n{traceback.format_exc()}"
        st.error(error_msg)
        return error_msg

def main():
    st.title("DeepSeek OCR Demo Page")
    st.markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.")
    
    with st.sidebar:
        st.header("ì„¤ì •")
        st.markdown("""
        ### ì‚¬ìš© ë°©ë²•
        1. ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. OCR ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”
        3. 'í…ìŠ¤íŠ¸ ì¶”ì¶œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        
        ### OCR ëª¨ë“œ
        - **ê¸°ë³¸ OCR**: ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
        - **ë§ˆí¬ë‹¤ìš´ ë³€í™˜**: ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        - **ì‚¬ìš©ì ì •ì˜**: ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì…ë ¥
        """)
        
        st.markdown("---")
        st.markdown("Powered by [DeepSeek OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)")
    
    with st.spinner("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë”© ì¤‘... ì²˜ìŒ ì‹¤í–‰ ì‹œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
        model, tokenizer = load_model()
    
    if model is None or tokenizer is None:
        st.error("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    st.success("ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    uploaded_file = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["jpg", "jpeg", "png", "bmp", "webp"]
    )
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
            st.image(image, use_container_width=True)
        
        with col2:
            st.subheader("OCR ì„¤ì •")
            
            task_option = st.radio(
                "OCR ëª¨ë“œ ì„ íƒ:",
                ["ê¸°ë³¸ OCR", "ë§ˆí¬ë‹¤ìš´ ë³€í™˜", "ì‚¬ìš©ì ì •ì˜"]
            )
            
            custom_prompt = None
            if task_option == "ê¸°ë³¸ OCR":
                prompt_type = "free_ocr"
                st.info("ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            elif task_option == "ë§ˆí¬ë‹¤ìš´ ë³€í™˜":
                prompt_type = "markdown"
                st.info("ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
            else:
                prompt_type = "custom"
                custom_prompt = st.text_area(
                    "í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                    placeholder="ì˜ˆ: Extract all text from this image.",
                    value="Extract all text from this image."
                )
            
            if st.button("í…ìŠ¤íŠ¸ ì¶”ì¶œ", type="primary"):
                with st.spinner("OCR ì²˜ë¦¬ ì¤‘... ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                    result = extract_text_from_image(model, tokenizer, image, prompt_type, custom_prompt)
                    
                    if result:
                        st.subheader("ê²°ê³¼")
                        if task_option == "ë§ˆí¬ë‹¤ìš´ ë³€í™˜":
                            st.markdown(result)
                        else:
                            st.text_area("ì¶”ì¶œëœ í…ìŠ¤íŠ¸", result, height=400)
                        
                        st.download_button(
                            label="ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                            data=result,
                            file_name="ocr_result.txt",
                            mime="text/plain"
                        )
                    else:
                        st.error("í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()